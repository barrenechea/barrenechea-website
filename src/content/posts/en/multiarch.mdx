---
title: Multi-arch All the Things
description: The journey from an x86/64 world to a universe of architectures.
pubDate: 2021-09-06T00:00:00Z
img: ~/assets/images/arm-x86.svg
imgAlt: Two chips, one labeled "x86" and the other labeled "ARM".
translatedBy: gpt-4-1106-preview
checksum: facf75ab9d5bc3c05e77ef62d401bc43f67681d096c323db1412b565a15cd49c
---

When we began laying our initial foundations at [Finalis](https://www.finalis.com), I remember having the idea to test AWS's Graviton.
It wasn't feasible in 2018 without building things yourself. Fast forward, it's 2022, and we (as a community) still struggle to find ARMv8 support in Dockerhub images.

But in 2020, something big happened: Apple announced the transition of Macs to Apple Silicon with a 2-year timeline.

At Finalis, we stick with Apple hardware for software development. You get a Unix-like Operating System and fantastic screen and audio quality for watching movies or whatever üçø.

In 2020, a countdown began. If we wanted to continue acquiring new Apple devices in the future, Finalis needed to become multi-architecture.

## Docker

When Apple released the M1, and we got one, Docker was starting to "get along" with it, but Docker on ARM had some issues in earlier versions simply because the engine was being tested (by us, the pioneering developers).

Later it seemed like everything was fine: third-party tools - most of the required images were already available for ARM64, but not all. [browserless](https://github.com/browserless/chrome) was the one I started tackling to get it built on ARM64, and so I sent a [pull request](https://github.com/browserless/chrome/pull/1847) with the minimum changes needed to make it work.

With third-party tools covered, it was a matter of making sure Docker built our own images for ARM64. "Hey, you use TypeScript; it should just work!"... Well, as long as your dependencies don't require downloading binaries while running `npm install`.

The main problem? No binaries are provided for ARM64, forcing a binary build while you run `npm install` with `make` (post-installation scripts?). From a configuration perspective, a little love in some of our `Dockerfile` files was all we needed and it solved everything.

## Pipelines

Working with GitHub Actions and dealing with multi-architecture, you have two options: run two parallel runners (one building for x86/64 and the other for arm64), or run one runner for both architectures.

I chose the second option to experiment, through [docker buildx](https://docs.docker.com/build/buildx/). Following the setup instructions for [build-push-action](https://github.com/docker/build-push-action#path-context) you can quickly get an operational pipeline.

Letting buildx handle the multi-architecture build allows you to push to Dockerhub without having to deal with different tags for different architectures. All your tags WILL be multi-architecture compatible.

The downside is the build time: having two parallel runners on their appropriate architectures would be much faster, but the pipeline would require managing the merging of the results into a single tag. _Only if you care about making it easier for consumers to find the right image._
